\section{Introduction}

The Description of Work describes Task 3.3 thus
\begin{quote}
Task 3.3: Develop tools and techniques to model, in an uniform way, the differences between different versions of
a system, which are parametrized or configured in different ways.
\end{quote}

\subsection{Behaviour refactoring}

The abstraction principle tells us that we must not repeat code. As
stated by \cite{pierce2002types} ``Each significant piece of functionality
in a program should be implemented in just one place in the source
code. Where similar functions are carried out by distinct pieces of
code, it is generally beneficial to combine them into one by abstracting
out the varying parts''. In practice we cannot always see what abstraction
we need until we have already replicated code. 

Having replicated code is bad because it forces us to make modifications
to the replicated code several times. We will eventually forget to
modify all the instances and we will go from having replicated code,
to having one subset of the bugs solved in one of the instances, and
another subset of them in the other one.

Erlang provides a mechanism for abstracting and parametrising implementations
at module level: \emph{Erlang behaviours}.

\subsection{\emph{Erlang behaviours}\label{sec:erlang_behaviours}}

\emph{Erlang Behaviours} are a standard Erlang mechanism that allows the
parametrisation of modules. A \emph{behaviour} is composed of:
\begin{itemize}
\item A \emph{behaviour definition}, which defines a series of callbacks
that its \emph{behaviour instances} must implement. This can be done
in one of two ways:

\begin{itemize}
\item Through \texttt{callback} declarations, which specify the expected
callbacks and their type signatures. For example:\begin{verbatim}
-callback terminate(Reason :: (normal | shutdown |
                               {shutdown, term()} |
                               term()),
                    State :: term()) -> term().
\end{verbatim}
\item Through a \texttt{behaviour\_info/1} function that specifies the name
and arity of the expected callbacks. For example:\begin{verbatim}
behaviour_info(callbacks) ->
                 [{init, 1}, {handle_call, 3},
                  {handle_cast, 2}, {handle_info, 2},
                  {terminate, 2}, {code_change, 3}];
behaviour_info(_) -> undefined.
\end{verbatim}
\end{itemize}

In this work we have only considered the \texttt{behaviour\_info/1}
function because, currently, there is limited support for \texttt{callback}
declarations by the abstract syntax tools. These two approaches are
mutually exclusive, the Erlang compiler will complain if both are
used at the same time.

\item One or more \emph{behaviour instances} which must implement the callbacks
defined by the \emph{behaviour definition} and contain a \texttt{behaviour}
declaration that specifies which \emph{behaviour definition} they
implement. \\
Example of \texttt{behaviour} declaration:\begin{verbatim}
-behaviour(gen_server).
\end{verbatim}
\end{itemize}

\subsection{Extended Finite State Machine Inference}

[FIXME: introduction]
[previous deliverables]

\section{Related Work}
\label{related_work}

Diverse approaches and studies have been aimed in the past...

\section{Assisted behaviour creation and unfolding with Wrangler}

In order to prevent code replication, it is usually possible and
convenient to abstract and parametrise those common parts of the implementation
into a single location, (typically another module), that can be invoked
from each of the individual, (not common), parts. Unfortunately, taking
this precaution requires an additional initial effort which may deter
developers from adopting it, in situations where time is limited.

We claim that this process can be automated to a large extent. By
introducing automation, we intend to help reduce the friction and
the likelihood of errors being introduced and, as a consequence, we
expect that parametrisation will be used more broadly as a replacement
for replication.

\subsection{Overview}

In this work we present a series of new refactorings for Wrangler tool
\cite{li2008refactoring}, which automate the creation and unfolding of Erlang
\emph{behaviour instances} (see Section~\ref{sec:erlang_behaviours}).
The refactorings are mostly written using Wrangler's \emph{DSL for composite
refactorings} \cite{li2012domain} and \emph{callback interface for
user-defined refactorings} \cite{li2011user}, but some parts were implemented
as internal extensions to Wrangler.

The main functionality can be summarised as follows:
\begin{itemize}
\item Creation of a single Erlang \emph{behaviour instance} from either:

\begin{itemize}
\item An existing function in a module
\item An expression in a module
\end{itemize}
\item Unfolding of a single \emph{behaviour instance} against its \emph{behaviour
definition}
\end{itemize}


\subsection{\emph{Behaviour} extraction\label{sec:behaviour-extraction}}

\emph{Behaviour} extraction creates a new \emph{behaviour callback} from an existing
piece of code, and it moves the code to a new or existing \emph{behaviour instance} so
that it is used by the \emph{behaviour instance} to implement the new
\emph{behaviour callback}.

It is supported by two alternative composite refactorings: \emph{Expression
to behaviour instance} and \emph{Function to behaviour instance}. Both
behave similarly, but the first one expects the user to select an expression
and it will automatically apply \emph{Function Extraction} to the expression
before the \emph{behaviour} instantiation. The second one assumes that the
behaviour callback implementation that must be extracted is already in a
separate function, and expects the user to select it.

Either way, the selected function will be moved to a new or existing
module (the \emph{behaviour instance}). The refactoring will ensure
that a \texttt{behaviour\_info/1} function is created if it does not
exist, and that the function moved is added to the \texttt{behaviour\_info/1}
function. It will also ensure that the \texttt{behaviour} declaration
is added to the \emph{behaviour instance} if it does not have it already. 

Internally, the composite refactorings call the following individual
refactorings in order:
\begin{itemize}
\item \emph{Create behaviour instance file} --- creates the \emph{behaviour
instance} if it does not exist. It prompts for the name of the module
to contain the \emph{behaviour instance} (see Section~\ref{sub:create_behav_instance})
\item \emph{Function Extraction} (only for \emph{Expression to behaviour
instance}) --- creates a new function with the selected expression.
It prompts for a name for the new function. No function with the provided
name should exist in the \emph{behaviour instance} nor the \emph{behaviour
declaration} (see Section~\ref{sub:fun_extraction})
\item \emph{Add function to behaviour\_info} --- adds the function to the
list of callbacks to implement by \emph{behaviour instances} (see
Section~\ref{sub:add_callback})
\item \emph{Move Function to Another Module} --- moves the implementation
of the function to the \emph{behaviour instance} (see Section~\ref{sub:move_fun})
\end{itemize}
A limitation of this process is that the generated calls to the functions
added to the \emph{behaviour instances} are statically targeted to
the specified \emph{behaviour instance}, (e.g: a call will have the
form \texttt{server:start()} where \texttt{server} is the name of
the \emph{behaviour instance} we just extracted, instead of \texttt{Module:start()}
where \texttt{Module} is a variable). For the \emph{behaviour} to
be able to use several \emph{behaviour instances}, it is necessary
that these static calls are generalised somehow.

For some scenarios, one way around this starts by using the existing
refactoring \emph{Generalise Function Definition} while selecting
the module name of the \emph{behaviour instance} used (this is explained
in more detail in Section~\ref{sub:adjustments-for-generalisation}).

We decided not to automate this process because it depends heavily
in the particular scenario, and multiple alternative possibilities
for the parametrisation are possible, (e.g: the definition of a macro,
or the inclusion of a variable in the state of a process, see 
Section~\ref{sub:alternative-adjustments-for-generalisation}).


\subsection{\emph{Behaviour} unfolding\label{sec:behaviour-unfolding}}

\emph{Behaviour} unfolding aims to reverse the process of \emph{behaviour}
extraction, i.e: the specific code in the \emph{behaviour instance}
is combined with a copy of the generic code in the \emph{behaviour
declaration}. A copy is made in order to ensure other \emph{behaviour
instances} keep working. This process is supported by the composite
refactoring \emph{Unfold behaviour instance}. This refactoring must
be called from the \emph{behaviour instance} to unfold and it takes
as input the name of the destination module.

The composite refactoring internally calls the following individual
refactorings in order:
\begin{itemize}
\item \emph{Copy module} --- copies the \emph{behaviour definition} to the
destination module name while updating only the references from the
current \emph{behaviour instance} (see Section~\ref{sub:copy_mod})
\item \emph{Instantiate calls} (optional step) --- instantiates the dynamic
calls with function names that match the \emph{behaviour} interface
in the new copy \emph{behaviour definition}, i.e: it will modify the
qualified calls whose module is not hard-coded by setting their target
module to the particular \emph{behaviour definition} specified (see
Section~\ref{sub:instantiate_calls})
\item \emph{Move function} --- moves the functions from the \emph{behaviour
instance} to the new copy of the \emph{behaviour definition} (see
Section~\ref{sub:move_fun})
\item \emph{Remove behaviour declaration} --- removes the \texttt{behaviour\_info/1}
function from the new copy of the \emph{behaviour definition} (see
Section~\ref{sub:remove_behav_dec})
\end{itemize}
A limitation of this process is that \emph{Instantiate calls} is only
an approximate solution to the problem of dynamic calls. Even though
this refactoring will instantiate the right calls correctly in the
majority of scenarios, it will not remove unused variables.

These variables must be removed by hand or else they will usually
produce compilation warnings, and clutter the code. In addition, in
the few cases where there may be dynamic calls to functions in other
modules, (i.e: not part of the \emph{behaviour}), with names that
match the ones in the \emph{behaviour} interface, the instantiation
may produce wrong results.

In these cases, the \emph{Instantiate calls} refactoring may be executed
individually, and each individual instantiation can then be checked
manually.

In some cases the \emph{Instantiate calls} refactoring may not be
necessary because the \texttt{?MODULE} macro is used for dynamic calls.
In these cases its application can be skipped by answering ``no''
when asked by the \emph{Unfold behaviour instance} refactoring about
instantiating dynamic calls.


\subsection{Basic refactorings}

In this section we provide an overview of the user-defined and primitive
refactorings used by the composite refactorings described in 
Sections~\ref{sec:behaviour-extraction}~and~\ref{sec:behaviour-unfolding}.


\subsubsection{Copy module\label{sub:copy_mod}}

This refactoring is based on the existing refactoring \emph{Rename
module}, and, as such, it was implemented as a primitive refactoring.
It will copy a module and update the external references to that module.
Unlike in the case of \emph{Rename module}, (where it would not make
sense), with \emph{Copy module} we can specify the list of modules
whose references we want to update. This way, the rest of modules
would keep pointing at the old version.


\subsubsection{Create \emph{behaviour instance} file\label{sub:create_behav_instance}}

This refactoring was implemented as an user-defined refactoring. It
takes as input a target module name. It creates a file for the module
if it does not exist, and it adds a \texttt{behaviour} declaration
to the file if it does not have it.


\subsubsection{Add function to \texttt{behaviour\_info/1}\label{sub:add_callback}}

This functionality was actually implemented as two alternative refactorings:
\begin{itemize}
\item \emph{Add function to behaviour\_info} --- adds a single pair \texttt{\{FunctionName,
Arity\}} to \texttt{behaviour\_info}
\item \emph{Add function name to behaviour\_info} --- adds a pair for each
of the functions that are defined in the module and have the name
specified (i.e: independently of their arity)
\end{itemize}
Both versions of the refactoring were implemented as user-defined
refactorings. Both create the \texttt{behaviour\_info} function if
it does not exist, and then add the functions specified to the list
of callbacks in it.

In order for the result of this refactoring to work, there must not
be any callback definitions in the \emph{behaviour definition} module.


\subsubsection{Remove \texttt{behaviour} declaration\label{sub:remove_behav_dec}}

This refactoring will search for the function \texttt{behaviour\_info/1}
and it will delete its implementation and remove it from every \texttt{export}
declaration in the module. If an \texttt{export} declaration only
contains that function, it will also be deleted.

It was implemented as an user-defined refactoring.


\subsubsection{Instantiate calls\label{sub:instantiate_calls}}

This refactoring tries to instantiate dynamic calls that target functions
of the \emph{behaviour} interface. It does so by searching for qualified
function calls with a target function name that corresponds to a function
from the \emph{behaviour} interface but with a module that is not
defined by an atom, (e.g: defined by a variable or a macro). And it
replaces the module with the name of the \emph{behaviour instance}
provided.

It was implemented as an user-defined refactoring.


\subsubsection{Move Function to Another Module\label{sub:move_fun}}

This refactoring was already part of Wrangler. It takes a function
and moves it with its local dependencies to a different module while
ensuring that all the references to the old function are updated.
It will also add the function to the list in the \texttt{export} declaration
if necessary.


\subsubsection{Function Extraction\label{sub:fun_extraction}}

This refactoring was already part of Wrangler. It takes an expression
an creates a new function for it. It also adds a parameter to the
function for each unbound variable within the expression.


\subsection{Example}

In this section we will go through a simple example of how the refactorings
described can be used to extract and unfold a \emph{behaviour instance}.


\subsubsection{Creating a \emph{behaviour} from scratch}

In Figure~\ref{fig:initial_code} we have provided a simple module
called \texttt{bar}. This module has two functions. The function \texttt{bar/0}
has the common behaviour, and the function \texttt{foo/0} has the
exclusive behaviour. In our case the exclusive behaviour is isolated
in a separate function, because of this we can set the cursor to point
to the function \texttt{foo/0} and use the refactoring \emph{Function
to behaviour instance}. If instead the function \texttt{bar/0} was
defined as follows:

\begin{verbatim}
bar() -> 42 + 1.
\end{verbatim}

We could still select the number 42, use the refactoring \emph{Expression
to behaviour instance}, and still obtain the same result.

\begin{figure}
\lstinputlisting[breaklines=true,captionpos=b,frame=tblr,label={lst:initial_code},
language=erlang]{figures/assisted_beh/code/step1/bar.erl}

\caption{Initial code\label{fig:initial_code}}
\end{figure}


When we execute the refactoring \emph{Function to behaviour instance},
we are asked about the ``Destination module'' which in our case
we called \texttt{new}. The refactoring will modify the module \texttt{bar}
to include the \texttt{behaviour\_info/1} function with our function
\texttt{foo/0} listed in it, and a new module \texttt{new} has been
created that contains the function \texttt{foo/0} and a \texttt{behaviour}
declaration that points to the module \texttt{bar}, (Figure~\ref{fig:after_ref}).

\begin{figure}
\begin{minipage}[t]{0.65\columnwidth}%
\lstinputlisting[breaklines=true,captionpos=b,frame=tbl,label={lst:bar_after_ref},language=erlang]{
figures/assisted_beh/code/step2/bar.erl}%
\end{minipage}%
\begin{minipage}[t]{0.35\columnwidth}%
\lstinputlisting[breaklines=true,captionpos=b,frame=tblr,label={lst:new_after_ref},language=erlang,showlines=true]{
figures/assisted_beh/code/step2/new.erl}%
\end{minipage}

\caption{Behaviour definition and instance after extraction\label{fig:after_ref}}
\end{figure}



\subsubsection{Adjustments for generalisation\label{sub:adjustments-for-generalisation}}

As stated before, we can see that a limitation of the refactoring
is that the call to function \texttt{foo/0} in \texttt{bar/0} has
the module \texttt{new} hard-coded. This would be a problem if we
wanted to replicate the module \texttt{new} to generate more \emph{behaviour
instances}, (\texttt{bar} is not generic enough).

In order to solve this, we can generalise the call by, for example,
selecting the module qualifier \texttt{new} in \texttt{bar/0}, and
applying the refactoring \emph{Generalise Function Definition}, (in
our case with the parameter name \texttt{Module}), and then moving
the generated \texttt{bar/0} function to the module \texttt{new} by
using the refactoring \emph{Move Function to Another Module} twice
(once to move \texttt{bar/0} to \texttt{new}, and once to bring \texttt{bar/1}
back to \texttt{bar} from \texttt{new}).

This procedure leaves us with the modules \texttt{bar} and \texttt{new}
shown in Figure~\ref{fig:manual_adj}.

\begin{figure}
\begin{minipage}[t]{0.6\columnwidth}%
\lstinputlisting[breaklines=true,captionpos=b,frame=tbl,label={lst:bar_manual_adj},language=erlang]{
figures/assisted_beh/code/step5/bar.erl}%
\end{minipage}%
\begin{minipage}[t]{0.4\columnwidth}%
\lstinputlisting[breaklines=true,captionpos=b,frame=tblr,label={lst:new_manual_adj},language=erlang,showlines=true]{
figures/assisted_beh/code/step5/new.erl}%
\end{minipage}

\caption{Behaviour definition and instance after adjustments for generalisation\label{fig:manual_adj}}
\end{figure}



\subsubsection{Alternative adjustments for generalisation\label{sub:alternative-adjustments-for-generalisation}}

The generalisation process described in Section~\ref{sub:adjustments-for-generalisation}
was not automated because it can be carried out by using several alternative
approaches which, in some cases, depend on the context of the implementation.
If the behaviour to use can be decided at compilation time it may
be generalised through the use of a macro (see Figure~\ref{fig:bar_manual_adj_b}).
\begin{figure}
\lstinputlisting[breaklines=true,captionpos=b,frame=tblr,label={lst:bar_manual_adj_b},
language=erlang]{figures/assisted_beh/code/step5b/bar.erl}

\caption{Alternative adjustments for generalisation 1\label{fig:bar_manual_adj_b}}
\end{figure}
If the behaviour represents a server, like is the case of \texttt{gen\_server},
the name of the \emph{behaviour instance} can be stored in the state
of the server or on the server dictionary (see Figure~\ref{fig:bar_manual_adj_c}).
\begin{figure}
\lstinputlisting[breaklines=true,captionpos=b,frame=tblr,label={lst:bar_manual_adj_c},
language=erlang]{figures/assisted_beh/code/step5c/bar.erl}

\caption{Alternative adjustments for generalisation 2\label{fig:bar_manual_adj_c}}
\end{figure}


Both alternatives remove the necessity of passing the name of the
\emph{behaviour instance} as a parameter. In exchange, the first approach
requires the decision to be taken at compilation time, (which is not
always possible), and the second one relies on side effects, (which
may eventually lead to integration errors that are harder to track).


\subsubsection{Unfolding a \emph{behaviour instance}}

For reverting the process we can call the refactoring \emph{Unfold
behaviour instance} from the \emph{behaviour instance} module. We
will be asked for a name to give to the resulting module, (in our
case we chose \texttt{bar\_new}), and whether we want to point all
dynamically-qualified callbacks to \texttt{new}, (in our case we chose
\texttt{yes}, in order to revert the adjustments made in Section~\ref{sub:adjustments-for-generalisation}).

This will produce a module \texttt{bar\_new} like the one shown in
Figure~\ref{fig:unfold_result}.

\begin{figure}
\lstinputlisting[breaklines=true,captionpos=b,frame=tblr,label={lst:unfold_result},
language=erlang]{figures/assisted_beh/code/step6/bar_new.erl}

\caption{Result of unfolding\label{fig:unfold_result}}
\end{figure}



\subsubsection{Removing spurious parameters}

We can see that both \texttt{bar/0} and \texttt{bar/1} in Figure~\ref{fig:unfold_result}
behave as \texttt{bar/0} in the Figure~\ref{fig:initial_code}, but
\texttt{bar/1} has a spurious parameter which will produce a warning.

For cleaner code we recommend manually removing the \texttt{bar/0}
function and transforming the function \texttt{bar/1} into \texttt{bar/0}
by removing the unused \texttt{Module} parameter, (whenever it is
unused, as is our case).

By doing this we will be left with the module \texttt{bar\_new} shown
in Figure~\ref{fig:final_result}.

\begin{figure}
\lstinputlisting[breaklines=true,captionpos=b,frame=tblr,label={lst:final_result},
language=erlang]{figures/assisted_beh/code/step7/bar_new.erl}

\caption{Result of unfolding after removing spurious parameter\label{fig:final_result}}
\end{figure}

\section{Automatic behaviour creation with Wrangler}

When developing software, we sometimes realise that we should add
abstraction after we have already implemented two pieces of similar
code. At this point, we must make an additional effort to find the
commonalities and unify them. This job is tedious and error prone,
and it does not provide any additional functionality, which makes
it difficult to justify. Nevertheless, it helps reduce maintenance
effort required in the future, and it will avoid the diversion in
the evolution of the code unified.

For this reason, in this section we study a mechanism that automatically
creates an Erlang behaviour by merging two modules selected by the
user, which are assumed to be structurally similar, and possibly the
result of copying and modifying one of them.

This mechanism has been implemented and distributed as a refactoring
included in Wrangler refactoring tool for Erlang. Even though there is no
guarantee about this, the refactoring aims to not alter the behaviour
of the two modules targeted from the point of view of their external
interface, and it should only affect the organisation of the code
between the original modules, (which will be transformed by the refactoring
into \emph{behaviour instances}), and the newly created \emph{behaviour
definition}.


\subsection{Related work}

Our approach has a lot in common with clone detection. The main difference
is that in this approach we assume that we know the root of the replication
and we are actually finding the different parts, and clone detection
assumes that most of the code is different and tries to find the commonalities.
In our case we assume that we start with two modules which are similar
and we try to find a common structure between both and create an Erlang
behaviour. For this reason the problem is not so much locating the
common parts but matching them appropriately. Thus, in our case it
makes more sense to explore structural commonalities in depth, whereas
in clone detection it is often more effective to focus on the sequential
behaviour.

The previous work that we have found which is most similar to the
one presented here is \cite{chawathe1996change}, which strongly
inspired this work. Tree comparison has been researched extensively
\cite{bille2005survey}, a big part targeted at XML \cite{peters2005change}.
Of course, the nature of XML is quite different to the one of Erlang,
but they both share the use of nested structures and semi-structured data.


\subsection{Overview}

The algorithm consists of three parts, tree matching, cluster construction,
and cluster linking. The process starts with two modules which are
assumed to be similar. First we find commonalities between their ASTs,
group the contiguous commonalities, move the commonalities to a separate
module, and link the pieces together with function calls in order
to preserve the original behaviour. This way we are left we three
modules, the remainings of the original ones and a new module with
the common parts.


\subsection{Tree matching\label{sub:tree-matching}}

In the first stage we apply a tree matching algorithm to find correspondences
between the ASTs, of both modules. In the current implementation we
have used the top-down tree matching algorithm described in \cite{al2005diffx},
because it is both easy to implement and effective. But we have encapsulated
the tree matching algorithm in a way that would allow it to be replaced
easily by other algorithms in the future.

In particular, we have found some more recent and heavily tuned algorithms
that might be have been more appropriate for our approach
\cite{falleri2014fine,fluri2007change}, but we
discarded them because, due to their complexity, reimplementing them would
have been much more costly, and in the cases where there exist public
implementations of them, they are written in different languages, which
would have made the integration more difficult and cumbersome.

One specific consideration for applying tree matching to our problem is
deciding how to compare individual nodes of the syntax tree. We use
a simple dual approach:
\begin{itemize}
\item For leave nodes, which usually contain the semantic information, we
compare the literal representation of the nodes. This way, two variables
or two atoms are considered equal if and only if their name matches.
It is important to remove any comments from the representation before
comparing, since this would produce false negatives.
\item For the rest of nodes, which contain structural information, we compare
the type of node and the number of children it has. This way, two
list constructors of the same length will be considered equal independently
of their elements, but a tuple and a list of the same length, or two
lists of different lengths, will not.
\end{itemize}
Tree matching provides us with a mapping between equivalent nodes
from one AST to the other. In Figure~\ref{fig:tree-mapping-example}
we show what a possible tree mapping representation would look like,
where nodes with the same name are considered equal.

\begin{figure}
\centering
\includegraphics[width=0.66\textwidth]{figures/automatic_beh_inf/diagrams/dia2}
\par

\caption{Graphical representaton of tree mapping\label{fig:tree-mapping-example}}
\end{figure}



\subsection{Cluster construction}

Cluster construction comprises the grouping of nodes in subtrees,
and the readjustment of frontiers. Readjustment of frontiers is achieved
through the resizing of the clusters.


\subsubsection{Creating common subtrees}

At this point we have a mapping between the common nodes of both the
ASTs of the input modules. We now traverse the AST of one of the input
modules and, we group in subtrees the pairs of contiguous nodes that
have a mapping. That is, we find those groups of mapped nodes that
are contiguous in both trees and the mapping.

A pair of nodes $a$ and $b$ in a tree, (parent and child respectively),
are contiguous if and only if: the parent of the projection of $b$
is identical to the projection of $a$, and $b$ is child of $a$
in the same position, (same number of child), than the projection
of $b$ is child of the projection of $a$.

Formally, we have two sets of nodes $N$ and $M$, (one per AST of
input module, where $a,b\in N$), a function $f$ that maps pairs
of common nodes from $N$ to $M$ ($f:N\rightarrow M$), (as returned
by the tree matching algorithm in Section~\ref{sub:tree-matching}),
and functions $p$ and $q$, that map a node to a tuple with its parent
(inside the same AST) and the ordinal position of the node in the
list of children of its parent, ($p:N\rightarrow(N,\mathbb{N})$ and
$q:M\rightarrow(M,\mathbb{N})$). Two nodes $a$ and $b$ are contiguous
if and only if: $\exists(i\in\text{\ensuremath{\mathbb{N}})}:(a,i)=p(b)\land(f(a),i)=q(f(b))$,
or $\exists(i\in\text{\ensuremath{\mathbb{N}})}:(b,i)=p(b)\land(f(a),i)=q(f(b))$,
or if there exists a node $c$ that is contiguous to both $a$ and
$b$.

In Figure~\ref{fig:tree-clustering-example} we show how the trees
in Figure~\ref{fig:tree-mapping-example} would be clustered.

\begin{figure}
\centering
\includegraphics[width=0.69\textwidth]{figures/automatic_beh_inf/diagrams/dia3}
\par

\caption{Graphical representation of tree clustering\label{fig:tree-clustering-example}}
\end{figure}



\subsubsection{Readjusting the frontiers}

Once we have grouped all mappings in clusters, (i.e: contiguous subtrees),
we must check that the frontiers, (i.e: the pairs of parent-child
nodes with nodes in different clusters), are valid places for function
extraction. There are several reasons why this may not be the case,
the most common ones are:
\begin{itemize}
\item The lower node of the frontier must be an expression. In particular,
it must be syntactically correct to use the subtree of the frontier
as the body of a function.
\item It must be possible to replace the child node with a function call.
For example, a function call cannot be introduced in the header of
a function instead of a parameter.
\item The variables defined in the child subtree cannot be used outside
of it since creating a function will also create a new scope. This
can be allowed at this point and fixed afterwards in some cases.
\end{itemize}
The conditions for readjusting frontiers are also useful for fine
tuning the algorithm. We can allow the creation of invalid functions
as long as we have a postprocessing mechanism that fixes them, (see
Section~\ref{sub:function-migration-artifact}), and we can disallow
the creation of functions that would be correct, if we want to preserve
some artifacts or for readability (see
Section~\ref{sub:artificial-block-expressions}).

We can adjust the frontiers by removing pairs of nodes from the common
clusters, and by removing their mappings. This produces a small replication
of code, but in the worst case scenario, we will fallback to having
no common clusters and that would leave the input modules as they
were originally.

We take as basic principle that, if necessary, we can have code common
to both instances replicated in both the behaviour instances, but
we cannot have code exclusive to one of the behaviour instances in
the behaviour definition. We could potentially do so by adding conditional
flow control expressions, but that would prevent future generalisation,
(the creation of new instances for the generated behaviour definition).


\subsubsection{Common clusters and exclusive clusters}

After we have computed the nodes that will form the clusters, we group
the nodes that are not mapped (and, as such, do not belong to any
cluster), into exclusive clusters. We will still only group contiguous
nodes in each cluster, but this time we will consider two nodes are
contiguous if and only if:
\begin{itemize}
\item One is ancestor of the other for any of the ASTs of the input modules
\item None of the nodes that link them together, (in the AST hierarchy),
has a mapping with a noose in the other AST, (i.e: it does not belong
to a common cluster).
\end{itemize}
We will now have two kinds of cluster:
\begin{itemize}
\item The common clusters, that have representation in both ASTs. Each of
them represents a function in the output behaviour definition (or
common functions).
\item The exclusive clusters, that in turn belong to one of the two ASTs.
Each of them represents a function in one of the behaviour instances
(or callbacks).
\end{itemize}
In Figure~\ref{fig:cluster-linking-example}, we show how the example
in Figure~\ref{fig:tree-clustering-example} would be reorganised
and linked, where the dashed node I in Version 2 is the rendering
of an indirection cluster.

\begin{figure}
\centering
\includegraphics[width=1\textwidth]{figures/automatic_beh_inf/diagrams/dia5}
\par

\caption{Graphical representation of linking\label{fig:cluster-linking-example}}


\end{figure}



\subsection{Linking}

The last step is linking the clusters through function calls, to preserve
the behaviour of the original modules after the relocation of the
functions.

For linking, we first visit every lower frontier of common clusters,
and try to assign the same name to both alternative child clusters.
For each lower frontier in the common clusters we necessarily have
two alternative child clusters, since nodes in the common clusters
are the result of merging two nodes. We also know that these two clusters
are different, since otherwise they would have merged to the parent
cluster. We can find which clusters are these by looking up the original
nodes in both of the original ASTs.

The alternative child clusters for a lower frontier do not need to
be exclusive. It is possible that one or both of the child clusters
are also common. This is because the end of the cluster may be due
to a discontinuity rather than to exclusive behaviours. If that is
the case, it is also possible that we have already set a name for
those clusters.

In order to create a uniform interface, we need to keep the symmetry
in both behaviour instances. This means having the same number of
callbacks in both instances, and having the same number of arguments
for each pair of equivalent callbacks.

Because of this, if we have already set a name for the cluster and,
thus, we cannot ensure that both child clusters have the same name,
we will create exclusive ``indirection clusters'' in any or both
of the sides that cannot be renamed. Indirection clusters have, as
only body, a call that redirects the execution flow to the correct
child cluster. Of course, we want to minimise the use of indirection
clusters, since they add complexity to the code.

We can keep the number of parameters for equivalent callbacks equal,
by mixing the parameters of both alternatives at any point. If there
are common parameters, we add them only once, but we will add exclusive
parameters to both alternatives of each cluster. In the exclusive
side where the exclusive parameters of the opposite side are not bound,
we will use dummy values for those parameters. These dummy values
will not cause a difference in the behaviour because they will not
be used, and they are easy to generate thanks to the flexible typing
of Erlang.

\subsection{Extra considerations}

The automatic behaviour extraction refactoring implies several logical
subrefactorings, and, thus, some considerations applied to these subrefactorings
are also applicable to automatic behaviour extraction. The main logical
subrefactorings implied by automatic behaviour extraction are: function
extraction, and function module migration, (i.e: moving one function
from one module to another).

But, of course, there are some considerations that are specific to
this refactoring as well.

\subsubsection{Artificial block expressions\label{sub:artificial-block-expressions}}

As we have mentioned before, when encapsulating code into functions,
we must ensure that the created functions are valid, and that it is
syntactically and grammatically correct to insert a function call
in the position where the extracted code originally was.

Additionally, it is desirable that when several consecutive sentences
are extracted, they are combined into the same created function. This
is not trivial if, as in our implementation, the clusters created
have tree topology. Splitting a tree horizontally will create several
subtrees, which would in turn translate into separate functions. But
it is much clearer to have them grouped in the body of the same function,
rather than in several different functions which are called consecutively,
(e. g: without the block artifact, the input example modules in Figure~\ref{fig:block-expression-input},
would be merged as shown in Figure~\ref{fig:block-expression-before},
the block artifact allows the more concise representation shown in
Figure~\ref{fig:block-expression-after}).

\begin{figure}
\begin{minipage}[t]{0.5\columnwidth}%
\lstinputlisting[breaklines=true,frame=tbl,language=Erlang]{figures/automatic_beh_inf/1-block_artifact/1-in/mod1.erl}%
\end{minipage}%
\begin{minipage}[t]{0.5\columnwidth}%
\lstinputlisting[breaklines=true,frame=tblr,language=Erlang]{figures/automatic_beh_inf/1-block_artifact/1-in/mod2.erl}%
\end{minipage}

\caption{Input example modules to illustrate block expression artifact\label{fig:block-expression-input}}


\end{figure}


\begin{figure}
\begin{minipage}[t]{0.5\columnwidth}%
\lstinputlisting[breaklines=true,frame=tbl,language=Erlang]{
figures/automatic_beh_inf/1-block_artifact/2-out-before/mod1.erl}%
\end{minipage}%
\begin{minipage}[t]{0.5\columnwidth}%
\lstinputlisting[breaklines=true,frame=tblr,language=Erlang]{
figures/automatic_beh_inf/1-block_artifact/2-out-before/mod2.erl}%
\end{minipage}

\begin{minipage}[t]{1\columnwidth}%
\lstinputlisting[breaklines=true,frame=tblr,language=Erlang]{
figures/automatic_beh_inf/1-block_artifact/2-out-before/out.erl}%
\end{minipage}

\caption{Output of modules in Figure~\ref{fig:block-expression-input} without
block expression artifact\label{fig:block-expression-before}}
\end{figure}


\begin{figure}
\begin{minipage}[t]{0.5\columnwidth}%
\lstinputlisting[breaklines=true,frame=tbl,language=Erlang]{
figures/automatic_beh_inf/1-block_artifact/3-out-after/mod1.erl}%
\end{minipage}%
\begin{minipage}[t]{0.5\columnwidth}%
\lstinputlisting[breaklines=true,frame=tblr,language=Erlang]{
figures/automatic_beh_inf/1-block_artifact/3-out-after/mod2.erl}%
\end{minipage}

\begin{minipage}[t]{1\columnwidth}%
\lstinputlisting[breaklines=true,frame=tblr,language=Erlang]{
figures/automatic_beh_inf/1-block_artifact/3-out-after/out.erl}%
\end{minipage}

\caption{Output of modules in Figure~\ref{fig:block-expression-input} with
block expression artifact\label{fig:block-expression-after}}
\end{figure}


In our implementation we solve this problem by doing two passes to
the algorithm, after the first one, we locate the consecutive child
clusters and we introduce an artificial block expression around them,
(in both source modules). In the second pass, the blocks will be extracted
as a single function, and we can remove them easily at postprocessing.
We also ensure that artificial blocks are not detached from their
child sentences by adding an exception for them in the frontier readjustment
procedure.


\subsubsection{Exported variables}

Variables bound in a sentence of a function are accessible from the
following sequences of the function, even though they are located
at sibling subtrees. Because of that, if we extract part of a function
that defines variables used afterwards, we will move those variables
to a new scope, they will no longer accessible by the sibling trees,
and we will cause a compilation error.

This problem can be prevented by ensuring, when adjusting the cluster
frontiers, that there are no variables exported to the parent cluster.
But when combined with the artificial block expression artifact, this
would be interfering, by preventing the extraction of bigger blocks
which could be fixed to preserve the semantics just by adding some
small artifacts, (see Section~\ref{sub:interference}).


\subsubsection{Exported variables in artificial block expressions\label{sub:interference}}

We can export variables from a function extracted as a block if we
make it return a tuple with the variables exported and we match them
outside of the function call.

But in some cases the result of the function may already be used from
outside, and modifying it would modify the behaviour of the refactored
program. To avoid this, whenever variables are exported, we will only
create artificial block expressions that do not contain the last sequence
of a clause. We do not have to worry about modifying the value of
intermediate sentences in clauses, because we know that this values
were discarded in the original code, (e.g: in the code of Figure~,
we cannot extract a common function for the whole clause of the case
expression because it both exports and returns values, but we can
create one function for the last sentence and one for the rest as
shown in Figure~). This will not produce an ideal solution in every
case, and it is only implemented for when the frontier is in a clause,
but without it the previous approaches would modify behaviour in cases
where values are returned and exported simultaneously from a clause.

\begin{figure}
\begin{minipage}[t]{0.5\columnwidth}%
\lstinputlisting[breaklines=true,frame=tbl,language=Erlang]{figures/automatic_beh_inf/2-interference/1-in/mod1.erl}%
\end{minipage}%
\begin{minipage}[t]{0.5\columnwidth}%
\lstinputlisting[breaklines=true,frame=tblr,language=Erlang]{figures/automatic_beh_inf/2-interference/1-in/mod2.erl}%
\end{minipage}

\caption{Input example modules to illustrate interference between artifacts\label{fig:interference-input}}
\end{figure}


\begin{figure}
\begin{minipage}[t]{1\columnwidth}%
\lstinputlisting[breaklines=true,frame=tblr,language=Erlang]{figures/automatic_beh_inf/2-interference/2-out/mod1.erl}%
\end{minipage}

\begin{minipage}[t]{1\columnwidth}%
\lstinputlisting[breaklines=true,frame=tblr,language=Erlang]{figures/automatic_beh_inf/2-interference/2-out/mod2.erl}%
\end{minipage}

\begin{minipage}[t]{1\columnwidth}%
\lstinputlisting[breaklines=true,frame=tblr,language=Erlang]{figures/automatic_beh_inf/2-interference/2-out/out.erl}%
\end{minipage}

\caption{Output of modules in Figure~\ref{fig:interference-input}\label{fig:interference-output}}
\end{figure}


In the second pass we will ensure that there are no exported variables,
(apart from those in artificial block expressions), to avoid breaking
other unusual kind of frontiers where we cannot automatically fix
the exportation of variables, (e.g: match expressions in the elements
of a list). In those cases we will still keep the code consistency
in exchange for some replication.


\subsubsection{Module migration and dependencies}

Moving functions between modules also requires some considerations.
The behaviour of functions that must be moved may depend on the macros
used on the original module. Moving them without moving the macros
would alter their behaviour. These macros may define or import records,
external functions or macro definitions. In addition, these macros
may include conditionals, (i.e: \texttt{ifdef}, \texttt{ifndef}, \texttt{else},
and \texttt{endif}). There is no easy solution to combine the macros
of both modules that will work for every case. Because of this, we
opted for a compromise solution that will probably work for most cases,
we treat the outer conditional blocks of macros as single macros,
and we copy all the macros blocks that provide dependencies used in
the code that has been moved to the common module.

Another consideration to have when moving functions is to check that
none of the existing functions in the destination module conflicts
with the ones we are moving, in our case this is made easier by the
fact that the destination module is new and, as such, there are no
previous existing functions. Nevertheless, something similar can happen
for function whose name is not generated automatically (see Section~\ref{sub:function-arity-collision}).


\subsubsection{Function migration artifact\label{sub:function-migration-artifact}}

The headers of functions in Erlang, as in many languages, are hard to
divide through function extraction. Not being able to divide them
means that if two functions are very similar but they have slightly
different patterns, we are forced to keep the whole header of the
function in the exclusive modules and abstract only the body of each
of the clauses.

Nevertheless, if they are completely identical we can still generalise
them without modifying the interface. Even though we cannot insert
function calls on the root of a module, we can insert a very simplified
version of the interface of the function, move the whole function to the
common module, and insert a simple indirection.

We do this by accepting as a valid frontier the division between the
header of a function and the root of the module, and by artificially
detaching, (i.e: removing from the mapping and common cluster), the
root of the module.

During postprocessing, we just have to generate the simplified function
header around the function call that is left in the place where the
original function was.


\subsubsection{Function arity collision\label{sub:function-arity-collision}}

Functions created in the common module may, at some point, need to
call the exclusive modules back. The right exclusive module to call
is the one that called the current function in the first place. For
Erlang to know which module to call we parametrise the destination
module of the function calls in the common module with a variable,
passed as a parameter by the calling module. This variable will contain
the name of the module as an atom at any particular time.

The solution is simple, but adding a parameter to common functions
will still modify its arity. This is not a problem when the names
of the functions are generated and each function has a different name.
But if the function has been moved from the exclusive modules and
has a name assigned by the user, it may potentially clash with a different
function which has the same name but different arity.

It is necessary to have this in consideration, and rename one of the
clashing functions as soon as this happens, in order to avoid altering
the behaviour of the original code.

\section{EFSM Inference}
\label{EFSMInference}

\subsection{EFSM Semantics}
\label{EFSMSemantics}

Extended Finite State Machines extend on conventional Finite State Machines by incorporating a \emph{data state} in addition to the \emph{control flow} state of the standard machine. This data state is described in \cite{EFSMs} as an n-dimensional space $D_{1} .. D_{n}$ that can store values. The transition labels are extended to incorporate \emph{guards} (called \emph{enabling functions} in \cite{EFSMs}) that are boolean functions over the data space. The available transitions of the machine depend not only on its control flow state (as is the case for FSMs) but also on its data state, as some transitions may be prevented by their guards. Additionally, EFSM transition labels contain \emph{update} transformations that modify the data state if the transition is executed. 

The model of EFSMs used in this paper extends on that from \cite{EFSMs}, where the guard and update transitions operated solely on the data state. The model used here makes the guard and update transitions functions over both the data state and the inputs. This allows the machine to express guards on parameterised, named events, and to incorporate input parameters into its data state.
  
An EFSM is formally defined as an 9-tuple $M = (S,L,I,O,D,G,U,F,T)$ where:

\begin{itemize}
\item{$S$ is a set of symbolic states}
\item{$L$ is an alphabet of event labels}
\item{$I$ is a vector space of inputs, $i_{1} .. i_{n}$}
\item{$O$ is a vector space of outputs, $o_{1} .. o_{n}$}
\item{$D$ is a vector space $r_{1} .. r_{n}$ that represents the internal \emph{data state} as a series of registers}
\item{$G$ is a set of boolean guard functions $g_{i} : (I \times D) \fun \bool$}
\item{$U$ is a set of update functions that compute a new data state from the inputs and the previous data state $u_{i} : (I \times D) \fun D$}
\item{$F$ is a set of output computation functions that produce the outputs from the data state and input parameters $f_{i} : (I \times D) \fun O$}
\item{$T$ is a transition matrix $T : (S \times S) \fun \powerset (L \times G \times U \times F)$}
\end{itemize}

This structure is very similar to the \emph{Stream X-Machine} presented in \cite{StreamXMachines}, only it does not model the \emph{streams} of inputs and outputs, instead treating them as instantaneous, external actions.

EFSMs are presented throughout this document as graphs, with the nodes representing the symbolic (or control flow) states from the set $S$, and the transitions labeled with representations of the $(L \times G)$ and $(U \times F)$ mappings for that transition. These are presented as a comma separated list of guard functions in square brackets, followed by a slash, and then a comma separated list of output and update functions in square brackets.

The update and output functions use the assignment syntax $:=$ to identify the value in the vector space that is computed. Any data state variables not computed explicitly are defined to be unchanged from their value before the transition; any input or output values that are not computed are assumed to be undefined (i.e. that input parameter is not present or that output value is not produced in this transition). Outputs and updates are represented using the same syntax. Outputs are presented immediately after the slash ($/$), while updates are inside square brackets.

The general form of a transition is: 

\begin{center}
$s_n \xrightarrow{e[g_1, .. g_n]/o_1, .. o_n[u_1, .. u_n]} s_m$ 
\end{center}

The arrow above represents a transition from state $S_n$ to $S_m$ with the event label $e$, restricted by guard expressions $g_1$ through $g_n$, producing outputs defined by $o_1$ through $o_n$, and updating the data state according to $u_1$ through $u_n$. The guard expressions are logically conjoined --- i.e. they must all be true for the transition to be allowed. Similarly, the output and update expressions should not be contradictory. In practice there will be one output or update expression for each output produced and each data state register that is altered. For example:

\begin{center}
$s_n \xrightarrow{vend[r_{2} \geq 100]/o_{1} :=r_{1}[r_{2} := r_{2} - 100]} s_m$
\end{center}

This arrow represents a transition that occurs with the event $vend$ when $r2$ is greater than 100, and produces the output with a value from the data space variable $r1$, and updates the data space variable $r2$ by subtracting 100 from the previous value. If there are no guard expressions or no outputs or updates then the relevant section can be omitted entirely:

\begin{center}
$s_1 \xrightarrow{select[i_{1}="coke"]} s_2$

$s_4 \xrightarrow{vend/o_{1} := r_{1}} s_5$
\end{center}

A simple EFSM model of a vending machine is shown in \fig{fig:vendsimple}. This shows a machine which begins with a $select$ operation that stores its input values ($i_1$ - the chosen drink) in data state register $r_1$. Then it allows $coin$ operations and increases the value of $r_2$ by the value of $i_1$ (the value of the inserted coin). A $vend$ operation is prevented by a guard expression until the value of $r_2$ reaches or exceeds 100. At this point a $vend$ operation can be performed which will decrease $r_2$ by 100 and output the selected product (stored in $r_1$).

\begin{figure}[here]
\begin{center}
\includegraphics[width=7cm]{vend-real.pdf}
\caption{A simple vending machine EFSM}
\label{fig:vendsimple}
\end{center}
\end{figure}

This model doesn't define any limits on the chosen products, nor does it allow the user to continue after the $vend$ operation. A more complicated model of a vending machine that keeps track of stock levels for two products and gives change is shown in \fig{fig:vendcomplicated}.

\begin{figure}[here]
\begin{center}
\includegraphics[width=13cm]{vend-complicated.pdf}
\caption{A more complicated machine EFSM}
\label{fig:vendcomplicated}
\end{center}
\end{figure}

\subsection{Guard and Update Expressions}
\label{Expressions}

The EFSM guard, update, and output expressions make use of various operators. Guard expressions use conventional comparison operators ($<, \leq, >, \geq$) and equality symbols ($=, \neq$) and have boolean values.

Update and output expressions use an assignment syntax of the form $o_n := <expression>$, where the expression has some appropriate value. Conventional arithmetic is supported ($+,-,*,/$), and literal values are enclosed in quotes (e.g. $"coke"$). Literals that are numeric are assumed to be converted automatically, so $o_1 := r_1 + "12"$ is valid. 

As well as the conventional comparison and arithmetic operators, this work introduces operators for string comparison and extraction. In many protocols the values that must be stored in the internal data state are not present in isolation, but as parts of larger blocks (network data packets, for example). The inference process described in \sect{Algorithm} is designed to operate without prior knowledge of the structure of the data. 

Consequently, the operators $match(pre,suf)$ and $get(pre,suf)$ are introduced to express the existence of values within strings, and to extract those values. They are designed to identify and extract vales by reference to prefix and suffix strings in the protocol. These can be the empty string, if the required value is consistently at the beginning or end of the string, or is the entirety of the string. 

As an example, consider a more complicated data packet representing the first transition in the vending machine example.

\begin{verbatim}
coinstate=0;selected=coke;cokeinv=12;pepsiinv=10;
\end{verbatim}

[definitions over numbers, bools, and strings]

\subsection{Inference algorithm}
\label{Algorithm}

\subsubsection{Prefix Tree Automaton generation}
\label{PTA}

[Retain trace number and event position in labels]

\begin{figure}[here]
\begin{center}
\includegraphics[width=12cm]{vend1.pdf}
\caption{The Prefix Tree Automaton (PTA) of the vending machine}
\label{fig:pta}
\end{center}
\end{figure}

\subsubsection{Identifying possible data reuse in traces}
\label{IntratraceDependencies}

[Trace formal def - inc EFSM events (label + params)]

\begin{figure}[here]
\begin{center}
\includegraphics[width=12cm]{intratracedeps.eps}
\caption{Some traces of the vending machine}
\label{fig:pta}
\end{center}
\end{figure}

[Identification of Intratrace dependencies]

[Formal def of Intratrace Deps]

[Formal def of trace and intradeps? or events with intradeps included?]

\subsubsection{Evidence Driven State Merging}
\label{EDSM}

[K-tails? Blue Fringe? Negatives?]

\subsubsection{Identifying co-incidence of data re-use}
\label{IntertraceDependencies}



[On merge check for matching trace deps]
[Example with diagrams]

\begin{figure}[here]
\begin{center}
\includegraphics[width=7cm]{vend2-withannotations.eps}
\caption{The FSM after simple merging}
\label{fig:FSM}
\end{center}
\end{figure}


[Variable instantiation. Consider newly identical transitions]
[Example with diagrams]

\subsubsection{Generalisation of transitions}
\label{Generalisation}

[FIXME Genetic Programming]


\section{Conclusions}
\label{concs}

The work reported here shows that we are able to automate the process of parametrising QuickCheck state machines -- that 
is extended finite-state machines -- in line with different versions or configurations of a system.

